{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build GPT-2 (small) from scratch and train on a (very) small dataset.\n",
    "\n",
    "- `MultiHeadAttention` class for masked MHA using `einsum` and `rearrange` from `einops`. \n",
    "- Model config, including the number of attention heads, the number of transformer blocks, and vocab size. Here we use a shorter context length (256 instead of the original 1024).\n",
    "- `ApproxGELU` class. The feedforward network of the transformer blocks use this approximation to GELU activation.\n",
    "- `TransformerBlock` class with pre-layernorm configuration.\n",
    "- `GPTVerdict` class. GPT-2 model to be trained on a text called \"The Verdict\".\n",
    "- Instantiate the model. The model has ~162 million parameters (the original GPT-2 has ~124 million because of weight tying).\n",
    "- Define functions to convert from text to token indexes and from token indexes to text, and to greedily generate token indexes.\n",
    "- Greedily generate a bit of text from the untrained model, just to check if everything's working.\n",
    "- Load the text to train on (in this case a short story called The Verdict).\n",
    "- Define the PyTorch dataset and a `create_dataloader` function.\n",
    "- Print out a trial batch in order to get a feel for how the dataloader works.\n",
    "- Define the train and val datasets and dataloaders.\n",
    "- Functions to evaluate the model (returning train and val losses) and to generate and print sample text.\n",
    "- Functions to train the model and plot losses.\n",
    "- Train the model or, if model already trained, load saved weights.\n",
    "- Function to generate text using top-k sampling. Print out some text generated using different values of k and different temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import GPT2Model\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_k, d_v, dropout,\n",
    "            context_length, n_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.wq = nn.Linear(d_model, n_heads * d_k, bias=qkv_bias)\n",
    "        self.wk = nn.Linear(d_model, n_heads * d_k, bias=qkv_bias)\n",
    "        self.wv = nn.Linear(d_model, n_heads * d_v, bias=qkv_bias)\n",
    "        self.linear = nn.Linear(n_heads * d_v, d_model) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', \n",
    "            torch.triu(torch.ones(context_length, context_length), \n",
    "            diagonal=1))    \n",
    "\n",
    "    def forward(self, x):\n",
    "        q = rearrange(self.wq(x), 'b t (h k) -> b h t k', h=self.n_heads)\n",
    "        k = rearrange(self.wk(x), 'b t (h k) -> b h t k', h=self.n_heads)\n",
    "        v = rearrange(self.wv(x), 'b t (h v) -> b h t v', h=self.n_heads)\n",
    "        attn = torch.einsum('bhtk, bhsk -> bhts', q, k) / self.d_k**0.5\n",
    "        mask_bool = self.mask.bool()[:x.size(1), :x.size(1)]\n",
    "        attn = attn.masked_fill(mask_bool, -torch.inf)\n",
    "        attn = F.softmax(attn, dim=3)\n",
    "        attn = self.dropout(attn)\n",
    "        out = torch.einsum('bhts, bhsv -> bhtv', attn, v)\n",
    "        out = rearrange(out, 'b h t v -> b t (h v)')\n",
    "        return self.linear(out) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 256,\n",
    "    'd_model': 768,\n",
    "    'd_k': 64,\n",
    "    'd_v': 64,\n",
    "    'n_heads': 12,\n",
    "    'n_blocks': 12,\n",
    "    'dropout': 0.2,\n",
    "    'qkv_bias': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproxGELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(0.79788456 * (x + 0.044715 * x**3)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(\n",
    "            cfg['d_model'], cfg['d_k'], cfg['d_v'], \n",
    "            cfg['dropout'], cfg['context_length'], \n",
    "            cfg['n_heads'], cfg['qkv_bias'])\n",
    "        self.ln1 = nn.LayerNorm(cfg['d_model'])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(cfg['d_model'], 4 * cfg['d_model']),\n",
    "            ApproxGELU(),\n",
    "            nn.Linear(4 * cfg['d_model'], cfg['d_model'])\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(cfg['d_model'])\n",
    "        self.dropout = nn.Dropout(cfg['dropout'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.dropout(self.attn(self.ln1(x)))\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.dropout(self.mlp(self.ln2(x)))\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTVerdict(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(cfg['vocab_size'], cfg['d_model'])\n",
    "        self.position_embedding = nn.Embedding(cfg['context_length'], cfg['d_model'])\n",
    "        self.dropout = nn.Dropout(cfg['dropout'])\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(cfg) for _ in range(cfg['n_blocks'])\n",
    "        ])\n",
    "        self.ln = nn.LayerNorm(cfg['d_model'])\n",
    "        self.out_head = nn.Linear(cfg['d_model'], cfg['vocab_size'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t = x.size()\n",
    "        x = self.token_embedding(x)\n",
    "        x = x + self.position_embedding(torch.arange(t, device=x.device))   \n",
    "        x = self.dropout(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTVerdict(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (position_embedding): Embedding(1024, 768)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): ApproxGELU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTVerdict(CONFIG)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 163,059,793 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to greedily generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_idxs_greedily(model, idx_batch, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        cropped_idx_batch = idx_batch[:, -context_size:] # idx_batch is (batch, n_tokens)\n",
    "        with torch.no_grad():\n",
    "            logits = model(cropped_idx_batch)                   \n",
    "        next_token_logits = logits[:, -1, :]  # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1) \n",
    "        next_token_idx = torch.argmax(next_token_probs, dim=-1, keepdim=True)  # (batch, 1)\n",
    "        idx_batch = torch.cat((idx_batch, next_token_idx), dim=1)  # (batch, n_tokens+1)\n",
    "    return idx_batch\n",
    "\n",
    "def text_to_idxs(text, tokenizer):\n",
    "    idxs = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return rearrange(torch.tensor(idxs), 'n -> 1 n')\n",
    "\n",
    "def idxs_to_text(idxs, tokenizer):\n",
    "    idxs = rearrange(idxs, '1 n -> n')\n",
    "    return tokenizer.decode(idxs.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedily generate text from untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I amiumBSD adolesc Or phantom Doctors involve rootbol Er\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "trial_start_context = \"Hello, I am\"\n",
    "\n",
    "model.eval() \n",
    "out = generate_idxs_greedily(model=model,\n",
    "                        idx_batch=text_to_idxs(trial_start_context, tokenizer),\n",
    "                        max_new_tokens=10,\n",
    "                        context_size=CONFIG[\"context_length\"]\n",
    "                        ) \n",
    "\n",
    "print(idxs_to_text(out, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data to train and evaluate model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of characters: 20479\n",
      "total number of tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "with open('data/the-verdict.txt', 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "print('total number of characters:', len(text_data))\n",
    "print('total number of tokens:', len(tokenizer.encode(text_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_ids = tokenizer.encode(text)\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        for i in range(0, len(self.token_ids) - max_length, stride):\n",
    "            input_chunk = self.token_ids[i:i+max_length]\n",
    "            target_chunk = self.token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(text, batch_size=4, max_length=256,\n",
    "                        stride=128, shuffle=True, drop_last=True):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(text, tokenizer, max_length, stride)   \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                shuffle=shuffle, drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial dataloader and batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  13,  198,  198,  ..., 1167, 2588,  856],\n",
       "         [ 198,  198, 6653,  ...,  284,  766,  340],\n",
       "         [  13,  679,  550,  ...,  198,  198,    1],\n",
       "         [ 262, 9074,   13,  ..., 1781,  286,  257]]),\n",
       " tensor([[  198,   198,     1,  ...,  2588,   856,   607],\n",
       "         [  198,  6653, 11441,  ...,   766,   340,    13],\n",
       "         [  679,   550, 17273,  ...,   198,     1,  1532],\n",
       "         [ 9074,    13,   536,  ...,   286,   257,  1178]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_dataloader = create_dataloader(text_data, batch_size=4, max_length=256,\n",
    "                                stride=1, shuffle=True, drop_last=True)\n",
    "\n",
    "trial_batch = next(iter(trial_dataloader))\n",
    "trial_batch     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and val datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(\n",
    "    train_data, batch_size=2, \n",
    "    max_length=CONFIG[\"context_length\"],\n",
    "    stride=CONFIG[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = create_dataloader(\n",
    "    val_data, batch_size=2, \n",
    "    max_length=CONFIG[\"context_length\"],\n",
    "    stride=CONFIG[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to evaluate model and to generate and print samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_dataloader, val_dataloader, device):\n",
    "    model.eval()\n",
    "    total_train_loss = 0.\n",
    "    total_val_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for input_batch, target_batch in train_dataloader:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            logits = model(input_batch)\n",
    "            logits = rearrange(logits, 'b t v -> (b t) v')\n",
    "            target_batch = rearrange(target_batch, 'b t -> (b t)')\n",
    "            loss = F.cross_entropy(logits, target_batch)\n",
    "            total_train_loss += loss.item()\n",
    "        for input_batch, target_batch in val_dataloader:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            logits = model(input_batch)\n",
    "            logits = rearrange(logits, 'b t v -> (b t) v')\n",
    "            target_batch = rearrange(target_batch, 'b t -> (b t)')\n",
    "            loss = F.cross_entropy(logits, target_batch)\n",
    "            total_val_loss += loss.item()\n",
    "    train_loss = total_train_loss / len(train_dataloader)\n",
    "    val_loss = total_val_loss / len(val_dataloader)\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, start_context, max_new_tokens):\n",
    "    model.eval()\n",
    "    idx_batch = text_to_idxs(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        idx_batch = generate_idxs_greedily(\n",
    "                model, idx_batch, max_new_tokens, \n",
    "                CONFIG[\"context_length\"]\n",
    "    )\n",
    "        print(idxs_to_text(idx_batch, tokenizer).replace(\"\\n\", \" \"))  \n",
    "    model.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader,\n",
    "                optimizer, criterion, device, n_epochs,\n",
    "                start_context, tokenizer, warmup_steps,\n",
    "                peak_lr = 5e-4, initial_lr=3e-5, min_lr=1e-6):\n",
    "    \n",
    "    train_losses, val_losses, track_lrs = [], [], []\n",
    "    global_step = -1\n",
    "\n",
    "    total_training_steps = len(train_dataloader) * n_epochs\n",
    "    lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_dataloader:\n",
    "            global_step += 1\n",
    "            optimizer.zero_grad()\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            logits = model(input_batch)\n",
    "            logits = rearrange(logits, 'b t v -> (b t) v')\n",
    "            target_batch = rearrange(target_batch, 'b t -> (b t)')\n",
    "\n",
    "            if global_step < warmup_steps:\n",
    "                lr = initial_lr + global_step * lr_increment  \n",
    "            else:\n",
    "                progress = ((global_step - warmup_steps) / \n",
    "                            (total_training_steps - warmup_steps))\n",
    "                lr = min_lr + (peak_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "            track_lrs.append(lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "            loss = criterion(logits, target_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            if global_step > warmup_steps:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss, val_loss = evaluate_model(model, train_dataloader, val_dataloader, device) \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer=tokenizer, \n",
    "                        start_context=start_context, \n",
    "                        max_new_tokens=50)    \n",
    "\n",
    "    return train_losses, val_losses, track_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs_seen, train_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()  \n",
    "    plt.savefig(\"images/train-val-loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model, or load saved weights if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GPTVerdict(CONFIG).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_epochs = 15\n",
    "start_context = \"Every effort moves you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skjda\\AppData\\Local\\Temp\\ipykernel_14564\\2787349940.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/gpt_verdict.pth'))\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('models/gpt_verdict.pth'):\n",
    "    model.load_state_dict(torch.load('models/gpt_verdict.pth'))\n",
    "\n",
    "else: \n",
    "    train_losses, val_losses, track_lrs = train_model(\n",
    "        model, train_dataloader, val_dataloader, \n",
    "        optimizer, criterion, device, n_epochs,  \n",
    "        start_context, tokenizer, warmup_steps=10\n",
    "    )\n",
    "\n",
    "    torch.save(model.state_dict(), 'models/gpt_verdict.pth')\n",
    "    epochs_tensor = torch.linspace(0, n_epochs, len(train_losses))\n",
    "    plot_losses(epochs_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('images/train-val-loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation using \"trained\" model and top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topk(model, start_context, context_size, max_new_tokens, \n",
    "                    top_k=None, temperature=0.0):\n",
    "    idx_batch = text_to_idxs(start_context, tokenizer).to(device)\n",
    "    for _ in range(max_new_tokens):\n",
    "        cropped_idx_batch = idx_batch[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(cropped_idx_batch)  \n",
    "        next_token_logits = logits[:, -1, :]  # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_k_logits, _ = torch.topk(next_token_logits, top_k, dim=-1)\n",
    "            min_val = top_k_logits[:, -1]\n",
    "            next_token_logits = torch.where(next_token_logits < min_val, \n",
    "                                            torch.ones_like(next_token_logits) * -float('inf'), \n",
    "                                            next_token_logits)\n",
    "    \n",
    "        if temperature > 0.0:\n",
    "            next_token_logits = next_token_logits / temperature\n",
    "            next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "            next_token_idx = torch.multinomial(next_token_probs, num_samples=1)\n",
    "\n",
    "\n",
    "        else:\n",
    "            next_token_idx = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if next_token_idx.item() == CONFIG['vocab_size'] - 1:\n",
    "            break\n",
    "        \n",
    "        idx_batch = torch.cat((idx_batch, next_token_idx), dim=1)\n",
    "    \n",
    "    print(idxs_to_text(idx_batch, tokenizer).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k: 1, temperature: 0.0\n",
      "Every effort moves you?\"  \"Oh, one of his pictures--so the me in a flash that he never thought of the fact, I had been, and\n",
      "top_k: 1, temperature: 0.5\n",
      "Every effort moves you?\"  \"I didn't--I felt him, the his history in the house.\"         \"I\n",
      "top_k: 1, temperature: 1.0\n",
      "Every effort moves you?\"  \"Oh, and he was his pictures--as the last word. \"Oh, and went on aing and in the donkey\n",
      "top_k: 1, temperature: 1.5\n",
      "Every effort moves you, I had been that, one of the with a deprecating of a flash that he never to me to have women had made him, I\n",
      "top_k: 1, temperature: 2.0\n",
      "Every effort moves you?\"    \"I glanced after--and--as the last he was when she began to me to me to the cigars you know.\n",
      "top_k: 3, temperature: 0.0\n",
      "Every effort moves you know,\" was one of the picture. Gisburn--as the last Gisburn's \"Yes--and I felt to have to the.\n",
      "top_k: 3, temperature: 0.5\n",
      "Every effort moves you?\"  \"I didn't. Gisburn--as you in a flash that he never thought of the fact, the cigars you know.\"\n",
      "top_k: 3, temperature: 1.0\n",
      "Every effort moves you?\"   I didn't--as he said to the me. Gisburn's an's I felt him, the cigars you know.\n",
      "top_k: 3, temperature: 1.5\n",
      "Every effort moves you know,\", on a little wild--as--I to the fellow enough--so it was no great that it, he had always been taken.\n",
      "top_k: 3, temperature: 2.0\n",
      "Every effort moves you?\" It was not that my dear, and he said--as you--had not to my work, and to have to have to me, I\n",
      "top_k: 5, temperature: 0.0\n",
      "Every effort moves you know,\" was one of the picture--I felt to say by his of a flash that he never thought of! The women had been you--it\n",
      "top_k: 5, temperature: 0.5\n",
      "Every effort moves you?\"  \"Oh, the last was dead.\" I. Stroud it was not till was, and in an unusual degree to the donkey\n",
      "top_k: 5, temperature: 1.0\n",
      "Every effort moves you in I had not--his one of the deep that with the end one of. Gisburn was dead up, I seemed to to the picture\n",
      "top_k: 5, temperature: 1.5\n",
      "Every effort moves you in the through my.\"  \"-- he's an--as. \"Yes, my work, and went on a smile that he said.\n",
      "top_k: 5, temperature: 2.0\n",
      "Every effort moves you say that he ch in the picture-- to the. The good fellow--as the: of my own and in him to have been out, so\n",
      "top_k: 10, temperature: 0.0\n",
      "Every effort moves you say that, and in the picture--I felt nervous and he had been in the house.\"        \"Oh,\n",
      "top_k: 10, temperature: 0.5\n",
      "Every effort moves you?\"  \"I--as he was his, and he was one in the last he never thought of the fact, had made him--his\n",
      "top_k: 10, temperature: 1.0\n",
      "Every effort moves you know that, on---that was his pictures--so it were days me back from the picture to go! The women.    \n",
      "top_k: 10, temperature: 1.5\n",
      "Every effort moves you say that to my surprise with a picture--the't of good.\"  \"The of the fact, his eyes grew to me. Gis\n",
      "top_k: 10, temperature: 2.0\n",
      "Every effort moves you know. \"Be--it was no one him, and I said with him when: of the moment, in an endless at.\" \"Oh\n",
      "top_k: 100, temperature: 0.0\n",
      "Every effort moves you?\"  \"--and his? I felt nervous and the his pictures--so it was no great surprise to me to me. Gisburn\n",
      "top_k: 100, temperature: 0.5\n",
      "Every effort moves you in the only- a little too? I felt nervous and he had always a little: \"Yes--that was _, I had been: \"\n",
      "top_k: 100, temperature: 1.0\n",
      "Every effort moves you of Hermia toI into a flash a little that he But fellow enough--thatas Jack Gisburn's have of the to brown in the\n",
      "top_k: 100, temperature: 1.5\n",
      "Every effort moves youdragged him. G one half nothing--I Mrs. single with him so that-- such to see! It Mrs. G was tired\n",
      "top_k: 100, temperature: 2.0\n",
      "Every effort moves you, have a monumental that my felt what so a little out him be but added was by,\" \" eyesoust herself fact brought to cry_!\" that\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "for top_k in [1, 3, 5, 10, 100]:\n",
    "    for temperature in [0.0, 0.5, 1.0, 1.5, 2.0]:\n",
    "        print(f'top_k: {top_k}, temperature: {temperature}')\n",
    "        generate_topk(model=model,\n",
    "                start_context=\"Every effort moves you\",\n",
    "                context_size=CONFIG[\"context_length\"],\n",
    "                max_new_tokens=30,\n",
    "                top_k=top_k,\n",
    "                temperature=temperature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_from_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
